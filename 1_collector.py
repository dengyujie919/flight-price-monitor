import pandas as pd
from amadeus import Client, ResponseError
from datetime import datetime, timedelta
import os
import time
import re
import sys

# --- 1. åˆå§‹åŒ–é…ç½® ---
def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)

API_KEY = os.environ.get('AMADEUS_CLIENT_ID')
API_SECRET = os.environ.get('AMADEUS_CLIENT_SECRET')

if not API_KEY or not API_SECRET:
    log("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° API å¯†é’¥ã€‚")
    sys.exit(1)

ORIGIN = 'SZX'        
DESTINATION = 'YIH'   
SCAN_DAYS = 30        
FILE_NAME = 'szx_yih_flight_data_cn.csv'

# --- 2. è¾…åŠ©å·¥å…·å‡½æ•° ---

def parse_duration(iso_duration):
    if not iso_duration: return ""
    hours = re.search(r'(\d+)H', iso_duration)
    minutes = re.search(r'(\d+)M', iso_duration)
    h_str = f"{hours.group(1)}å°æ—¶" if hours else ""
    m_str = f"{minutes.group(1)}åˆ†" if minutes else ""
    return h_str + m_str

def calculate_layover(segments):
    if len(segments) < 2: return "æ— ", "0"
    total_wait_seconds = 0
    layover_locs = []
    for i in range(len(segments) - 1):
        layover_locs.append(segments[i]['arrival']['iataCode'])
        arr = datetime.strptime(segments[i]['arrival']['at'], "%Y-%m-%dT%H:%M:%S")
        dep = datetime.strptime(segments[i+1]['departure']['at'], "%Y-%m-%dT%H:%M:%S")
        total_wait_seconds += (dep - arr).total_seconds()
    return "/".join(layover_locs), f"{int(total_wait_seconds // 3600)}h{int((total_wait_seconds % 3600) // 60)}m"

# --- 3. ä¸»ç¨‹åº ---

def run_daily_scan():
    # å…³é—­ debug æ¨¡å¼ï¼Œä¿æŒæ¸…çˆ½
    amadeus = Client(client_id=API_KEY, client_secret=API_SECRET)
    
    fetch_date = datetime.now().strftime('%Y-%m-%d')
    today = datetime.now()
    buffer_data = []

    log(f"ğŸš€ å¼€å§‹é‡‡é›†: {ORIGIN} -> {DESTINATION} (æœªæ¥ {SCAN_DAYS} å¤©)")
    log("-" * 50)

    for i in range(1, SCAN_DAYS + 1):
        target_date = (today + timedelta(days=i)).strftime('%Y-%m-%d')
        # ç´§å‡‘å‹è¿›åº¦æ‰“å°
        progress = f"ğŸ” [{i:02d}/{SCAN_DAYS}] {target_date}"
        
        try:
            response = amadeus.shopping.flight_offers_search.get(
                originLocationCode=ORIGIN,
                destinationLocationCode=DESTINATION,
                departureDate=target_date,
                adults=1
            )
            
            if not response.data:
                print(f"{progress} -> â„¹ï¸ æ— èˆªç­", flush=True)
                continue

            daily_flights = []
            for flight in response.data:
                itinerary = flight['itineraries'][0]
                segments = itinerary['segments']
                
                daily_flights.append({
                    'é‡‡é›†æ—¥æœŸ': fetch_date,
                    'èµ·é£æ—¥æœŸ': target_date,
                    'æå‰å¤©æ•°': i,
                    'èˆªç­å·': segments[0]['carrierCode'] + segments[0]['number'],
                    'èˆªå¸': flight['validatingAirlineCodes'][0],
                    'ç±»å‹': "ç›´é£" if len(segments) == 1 else "ä¸­è½¬",
                    'èµ·é£æ—¶é—´': segments[0]['departure']['at'].split('T')[1][:5],
                    'åˆ°è¾¾æ—¶é—´': segments[-1]['arrival']['at'].split('T')[1][:5],
                    'æ€»æ—¶é•¿': parse_duration(itinerary['duration']),
                    'ä¸­è½¬åœ°': calculate_layover(segments)[0],
                    'ä¸­è½¬æ—¶é•¿': calculate_layover(segments)[1],
                    'å‰©ä½™åº§ä½': flight['numberOfBookableSeats'],
                    'ä»·æ ¼': float(flight['price']['total']),
                    '_dept': segments[0]['departure']['at'],
                    '_arr': segments[-1]['arrival']['at']
                })

            if daily_flights:
                df = pd.DataFrame(daily_flights)
                df = df.sort_values(by='ä»·æ ¼').drop_duplicates(subset=['_dept', '_arr'], keep='first')
                df = df.drop(columns=['_dept', '_arr'])
                buffer_data.append(df)
                print(f"{progress} -> âœ… æŠ“å–åˆ° {len(df)} æ¡æ•°æ®", flush=True)

        except ResponseError as e:
            print(f"{progress} -> âŒ APIé”™è¯¯: {e}", flush=True)
        
        time.sleep(0.2) # ç¨å¾®ç¼©çŸ­é—´éš”

   # --- ä¿å­˜é€»è¾‘ ---
    if buffer_data:
        final_df = pd.concat(buffer_data, ignore_index=True)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»å­˜åœ¨
        file_exists = os.path.isfile(FILE_NAME)
        
        if not file_exists:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶ï¼ŒåŒ…å«è¡¨å¤´
            final_df.to_csv(FILE_NAME, index=False, encoding='utf-8-sig')
            log(f"âœ¨ é¦–æ¬¡è¿è¡Œï¼Œå·²åˆ›å»ºæ–°æ–‡ä»¶: {FILE_NAME}")
        else:
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œä½¿ç”¨ mode='a' (append) è¿½åŠ æ•°æ®
            # header=False è¡¨ç¤ºä¸é‡å¤å†™å…¥è¡¨å¤´
            final_df.to_csv(FILE_NAME, mode='a', index=False, header=False, encoding='utf-8-sig')
            log(f"ğŸ’¾ æ•°æ®å·²è¿½åŠ è‡³ç°æœ‰æ–‡ä»¶: {FILE_NAME}")
    else:
        log("âš ï¸ æœ¬æ¬¡æœªé‡‡é›†åˆ°æ•°æ®ï¼Œæ–‡ä»¶æœªæ›´æ–°ã€‚")
if __name__ == "__main__":
    run_daily_scan()